{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import datetime\n",
    "import numpy as np\n",
    "import warnings\n",
    "%matplotlib inline\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data1_in = pd.read_csv('../Data/data1/data1.csv')\n",
    "data2_in = pd.read_csv('../Data/data2/data2.csv')\n",
    "data3_in = pd.read_csv('../Data/data3/data3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "drop_cols = ['login_sum','login_max','loginvar','loginmean','login_3_cnt','login_week_cnt','device_map'] + ['page_sum','page_0_sigle','page_1_sigle','page_2_sigle','page_3_sigle','page_4_sigle',\n",
    "                 'action_type_sum','action_type_0_sigle','action_type_1_sigle','action_type_2_sigle',\n",
    "                 'action_type_3_sigle','action_type_4_sigle','action_type_5_sigle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "select_cols = ['user_id','label'] + ['login_day_min', 'device_type', 'login_week_arg_cnt', 'register_type',\n",
    "       'act_last_cnt', 'login_day_std', 'action_type_0', 'act_week_cnt',\n",
    "       'page_1', 'act_3_cnt', 'login_cnt', 'page_0', 'act_day_std', 'actmean',\n",
    "       'page_2', 'login_3_arg_cnt', 'register_day', 'act_sum', 'act_cnt',\n",
    "       'action_type_1', 'action_type_2', 'act_day_min', 'actvar',\n",
    "       'act_day_max', 'act_max', 'page_3', 'video_last_cnt', 'action_type_3',\n",
    "       'page_4', 'video_3_cnt', 'videomean', 'video_sum', 'is_author',\n",
    "       'page_3_7_cnt', 'action_type_1_7_cnt', 'video_day_min',\n",
    "       'video_week_cnt', 'action_type_0_7_cnt', 'video_day_max', 'video_cnt',\n",
    "       'videovar', 'action_type_2_7_cnt', 'page_3_3_cnt', 'video_day_std',\n",
    "       'action_type_0_1_cnt', 'action_type_0_3_cnt', 'action_type_5',\n",
    "       'action_type_1_3_cnt', 'page_0_1_cnt', 'video_max', 'page_0_7_cnt',\n",
    "       'page_0_3_cnt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mapDeviceType(thread_value=0.5):\n",
    "    con_data = pd.concat([data1_in, data2_in])\n",
    "    index = con_data['label'].groupby(con_data[\"device_type\"]).mean().index\n",
    "    values = con_data['label'].groupby(con_data[\"device_type\"]).mean().get_values()\n",
    "    return index[values>thread_value]\n",
    "\n",
    "good_index = mapDeviceType()\n",
    "\n",
    "data1_in['device_map'] = data1_in['device_type'].apply(lambda x: int(x in good_index))\n",
    "data2_in['device_map'] = data1_in['device_type'].apply(lambda x: int(x in good_index))\n",
    "data3_in['device_map'] = data1_in['device_type'].apply(lambda x: int(x in good_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data1 = data1_in[[c for c in data1_in.columns if c not in drop_cols and c in select_cols]]\n",
    "data2 = data2_in[[c for c in data2_in.columns if c not in drop_cols and c in select_cols]]\n",
    "data3 = data3_in[[c for c in data3_in.columns if c not in drop_cols and c in select_cols]]\n",
    "\n",
    "# data1 = data1_in[[c for c in data1_in.columns if c not in drop_cols]]\n",
    "# data2 = data2_in[[c for c in data2_in.columns if c not in drop_cols]]\n",
    "# data3 = data3_in[[c for c in data3_in.columns if c not in drop_cols]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22342, 54)\n",
      "(26571, 54)\n",
      "(51709, 53)\n"
     ]
    }
   ],
   "source": [
    "print (data1.shape)\n",
    "print (data2.shape)\n",
    "print (data3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CV调参法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_n_estimators = {'n_estimators': list(range(100,500,10))}\n",
    "param_learning_rate = {'learning_rate':[0.005,0.01,0.02,0.05,0.1,0.2,0.5]}\n",
    "\n",
    "param_max_depth = {'max_depth':list(range(3,9,1))}\n",
    "param_num_leaves = {'num_leaves':list(range(10,100,5))}\n",
    "\n",
    "param_subsample = {'subsample':list(np.arrage(0.5,1,0.1))}\n",
    "param_max_bin = { 'max_bin':list(range(5,50,5))}\n",
    "param_min_data_in_leaf = {'min_data_in_leaf':list(range(10,200,5))}\n",
    "param_feature_fraction = {'feature_fraction':list(np.arange(0.1,1.0,0.1))}\n",
    "# param_bagging_fraction = {'bagging_fraction':list(np.arange(0.1,1.0,0.1))}\n",
    "param_lambda_l1 = {'lambda_l1':list(np.arange(0.1,1.0,0.1))}\n",
    "param_lambda_l2 = {'lambda_l2':list(np.arange(0.1,1.0,0.1))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_acc1 = {'max_depth':list(range(3,9,1)), 'num_leaves':list(range(8,200,4))}\n",
    "param_acc2 = {'max_bin':list(range(1,50,5)), 'min_data_in_leaf':list(range(10,200,5))}\n",
    "param_guonihe1 = {'feature_fraction':list(np.arange(0.1,1.0,0.1)), 'bagging_fraction':list(np.arange(0.1,1.0,0.1))}\n",
    "param_guonihe2 = {'lambda_l1':list(np.arange(0.1,1.0,0.1)), 'lambda_l2':list(np.arange(0.1,1.0,0.1))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LGBM = lgb.LGBMClassifier( \n",
    "#                     max_depth=3,\n",
    "                    n_estimators = 270,\n",
    "                    learning_rate =0.1,     \n",
    "                    objective = 'binary',\n",
    "#                     num_leaves=8,\n",
    "                    boosting_type='dart',\n",
    "#                     feature_fraction=0.4,\n",
    "#                     bagging_fraction=0.9,\n",
    "#                     lambda_l2=0.5,\n",
    "#                     lambda_l1=0.7,\n",
    "#                     min_data_in_leaf=15,\n",
    "#                     max_bin=40\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.concat([data1, data2])\n",
    "train.pop('user_id')\n",
    "label = train.pop('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv1 = GridSearchCV(estimator = LGBM,\n",
    "                  param_grid = param_acc1, scoring='f1', iid=False)\n",
    "cv1.fit(train, label)\n",
    "cv1.grid_scores_, cv1.best_params_, cv1.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "————————————————————————————————————————————————————————"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sroceF1(pred, real):\n",
    "    M = set(pred)\n",
    "    N = set(real)\n",
    "    Precision = len(M.intersection(N))/len(M)\n",
    "    Recall = len(M.intersection(N))/len(N)\n",
    "    F1 = 2*Precision*Recall/(Precision+Recall)\n",
    "\n",
    "    print(\"Precision=\",Precision,\"| Recall=\",Recall)\n",
    "    print(\"F1=\",F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def buildModelAndPredict(isOnLine=True, isTest=False, yuzhi=0.5, model=lgb.LGBMClassifier(  max_depth=3,\n",
    "                                                                    n_estimators = 120,\n",
    "                                                                    learning_rate = 0.05,     \n",
    "                                                                    objective = 'binary',\n",
    "                                                                    subsample = 0.7,\n",
    "                                                                    colsample_bytree = 0.74,\n",
    "                                                                    num_leaves = 8)\n",
    "                        ):\n",
    "    if (isOnLine):\n",
    "        # yuzhi=0.4\n",
    "        train = pd.concat([data1, data2])\n",
    "        test = data3.copy()\n",
    "        train.pop('user_id')\n",
    "        label = train.pop('label')\n",
    "        \n",
    "        model.fit(train, label)\n",
    "        user_list = test.pop('user_id')\n",
    "        print (len(user_list))\n",
    "        user_df = pd.DataFrame(user_list)\n",
    "        user_df['pre_act'] = model.predict_proba(test)[:,1]\n",
    "        return user_df[user_df.pre_act>yuzhi]['user_id']\n",
    "            \n",
    "    else: \n",
    "        train = data1.copy()\n",
    "        test = data2.copy()\n",
    "        # train pop user_id and get label\n",
    "        train.pop('user_id')\n",
    "        train_df_label = train.pop('label')\n",
    "        train_df = train\n",
    "        \n",
    "        # test get user_id and pop label\n",
    "        real_user = test[test.label==1]['user_id']\n",
    "        user_list = test.pop('user_id')\n",
    "        test.pop('label')\n",
    "        test_df = test\n",
    "        \n",
    "        user_df = pd.DataFrame(user_list)\n",
    "        # train the model and predict\n",
    "        model.fit(train_df, train_df_label)\n",
    "        user_df['pre_act'] = model.predict_proba(test_df)[:,1]\n",
    "        \n",
    "        # calculate the F1 score\n",
    "        if (isTest):\n",
    "            for i in np.arange(0.3, 0.8, 0.05):\n",
    "                user_pre = user_df[user_df.pre_act>i]['user_id']\n",
    "                sroceF1(user_pre, real_user)\n",
    "                print (i)\n",
    "        else:\n",
    "            user_pre = user_df[user_df.pre_act>yuzhi]['user_id']\n",
    "            print (len(user_pre),len(real_user))\n",
    "            sroceF1(user_pre, real_user)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51709\n"
     ]
    }
   ],
   "source": [
    "user_pre = buildModelAndPredict(isOnLine=True, isTest=False, yuzhi=0.4, model=LGBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24790"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(user_pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 结果数据提交"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_pre.to_csv('../Output/result0609_tiaocan.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
