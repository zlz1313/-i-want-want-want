{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import datetime\n",
    "import numpy as np\n",
    "import warnings\n",
    "%matplotlib inline\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "users = pd.read_csv('../Data/raw_data/user_register_log.txt', header=None,names=['user_id','register_day','register_type','device_type'],sep='\\t') # 注册用户数据加载\n",
    "user_login = pd.read_csv('../Data/raw_data/app_launch_log.txt', header=None,names=['user_id','day'],sep='\\t') # app登录日志数据加载\n",
    "user_act = pd.read_csv('../Data/raw_data/user_activity_log.txt', header=None,names=['user_id','day','page','video_id','author_id','action_type'],sep='\\t') # 用户行为日志数据加载\n",
    "user_video = pd.read_csv('../Data/raw_data/video_create_log.txt', header=None,names=['user_id','day'],sep='\\t') # 用户拍摄视频日志数据加载"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所有数据都是1-30天内的数据\n",
    "\n",
    "且无缺失值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 对数据进行滑窗法划分："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data: \n",
    "\n",
    "    +-data1\n",
    "        --feature:1-15;label:16-22\n",
    "    +-data2\n",
    "        --feature:9-23;label:24-30\n",
    "    +-data3\n",
    "        --feature:1-30;label: 31-37"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def cutDataFunc(data, cut_col ,start_day, end_day):\n",
    "    return data[(data[cut_col]<=end_day)&(data[cut_col]>=start_day)]\n",
    "\n",
    "def cutDataByTime(data_url, start_day, end_day):\n",
    "    temp_users = cutDataFunc(users, 'register_day', start_day, end_day)\n",
    "    temp_login = cutDataFunc(user_login, 'day', start_day, end_day)\n",
    "    temp_act = cutDataFunc(user_act, 'day', start_day, end_day)\n",
    "    temp_video = cutDataFunc(user_video, 'day', start_day, end_day)\n",
    "    \n",
    "    temp_users.to_csv(data_url+'users.csv',index=False)\n",
    "    temp_login.to_csv(data_url+'login.csv',index=False)\n",
    "    temp_act.to_csv(data_url+'act.csv',index=False)\n",
    "    temp_video.to_csv(data_url+'video.csv',index=False)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cutDataProgram():\n",
    "    print (\"---------START-----------\")\n",
    "    \n",
    "    cutDataByTime('../Data/data1/train_', 1, 15)\n",
    "    cutDataByTime('../Data/data1/test_', 16, 22)\n",
    "    print (\"-----第1数据集完成-------\")\n",
    "    \n",
    "    cutDataByTime('../Data/data2/train_', 9, 23)\n",
    "    cutDataByTime('../Data/data2/test_', 24, 30)\n",
    "    print (\"-----第2数据集完成-------\")\n",
    "    \n",
    "    cutDataByTime('../Data/data3/train_', 1, 30)\n",
    "    print (\"-----第3数据集完成-------\")\n",
    "    \n",
    "    print (\"----------END------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------START-----------\n",
      "-----第1数据集完成-------\n",
      "-----第2数据集完成-------\n",
      "-----第3数据集完成-------\n",
      "----------END------------\n"
     ]
    }
   ],
   "source": [
    "cutDataProgram()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train集构造和标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 获取最近一天的点击数量\n",
    "def getCntOfOneDay(data):\n",
    "    return sum(data[(data.day==0)]['cnt'].values)\n",
    "\n",
    "# 获取最近一段时间内的点击数量\n",
    "def getCntOfSomeDay(data, day_len=7):\n",
    "    return sum(data[(data.day>=0) & (data.day<day_len)]['cnt'].values)\n",
    "\n",
    "# 获取最近一段时间内的点击数量（改进版，可以自由选择col统计）\n",
    "def getCntOfSomeDayWithCol(data, day_len=1, col='page'):\n",
    "    return sum(data[(data.day>=0) & (data.day<day_len)][col].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 获取有活跃行为的用户集，（从test集中获取）\n",
    "def getActivityUsers(data_url):\n",
    "    test_login = pd.read_csv(data_url+'test_login.csv')\n",
    "    test_act = pd.read_csv(data_url+'test_act.csv')\n",
    "    test_video = pd.read_csv(data_url+'test_video.csv')\n",
    "    \n",
    "    activity_user = np.unique(pd.concat([test_login['user_id'], test_act['user_id'], test_video['user_id']]))\n",
    "    return activity_user\n",
    "\n",
    "# （video and lanuch）data create feature method\n",
    "# 1、将day转换成距离时间窗口截点的距离\n",
    "# 2、描述性day、cnt统计特征\n",
    "# 3、连续1、 2、 3、 7天内的统计特征\n",
    "def getCountFeature(data, name='login'):\n",
    "    day_max = max(data['day'])\n",
    "    data['day'] = day_max - data.day\n",
    "    df = data.groupby(['user_id','day'],as_index=False).apply(lambda x:x.shape[0])\n",
    "    df_temp = pd.DataFrame(df, columns=['cnt']).reset_index()\n",
    "    res_df = df_temp.groupby(['user_id'],as_index=False).agg({'day':['max','min','std'],'cnt':['count','sum','max','var','mean']})\n",
    "    res_df.columns = ['user_id', name+'_day_max',name+'_day_min',name+'_day_std',name+'_cnt',name+'_sum',name+'_max',name+'var',name+'mean']\n",
    "    \n",
    "    res_df[name+'_last_cnt'] = df_temp.groupby(['user_id'], as_index=False).apply(lambda x:getCntOfOneDay(x))\n",
    "    res_df[name+'_2_cnt'] = df_temp.groupby(['user_id'], as_index=False).apply(lambda x:getCntOfSomeDay(x, 2))\n",
    "    res_df[name+'_2_arg_cnt'] = res_df[name+'_2_cnt'] / 2\n",
    "    res_df[name+'_3_cnt'] = df_temp.groupby(['user_id'], as_index=False).apply(lambda x:getCntOfSomeDay(x, 3))\n",
    "    res_df[name+'_3_arg_cnt'] = res_df[name+'_3_cnt'] / 3\n",
    "    res_df[name+'_week_cnt'] = df_temp.groupby(['user_id'], as_index=False).apply(lambda x:getCntOfSomeDay(x))\n",
    "    res_df[name+'_week_arg_cnt'] = res_df[name+'_week_cnt'] / 7\n",
    "    return res_df.fillna(0)\n",
    "\n",
    "# act: create feature method\n",
    "# 1、将day转换成距离时间窗口截点的距离\n",
    "# 2、描述性day、cnt统计特征\n",
    "# 3、连续1、 2、 3、 7天内的统计特征\n",
    "# 4、page和action_type不同类型的所有统计数以及比率特征\n",
    "# 5、page和action_type不同类型在连续1、 3、 7天内的统计特征\n",
    "# 6、user_id是否为author_id的成员\n",
    "def getCountFeatureAboutAct(data, name='act'):\n",
    "    day_max = max(data['day'])\n",
    "    data['day'] = day_max - data.day\n",
    "    authors = set(data['author_id'])\n",
    "    \n",
    "    df = data.groupby(['user_id','day'],as_index=False).apply(lambda x:x.shape[0])\n",
    "    df_temp = pd.DataFrame(df, columns=['cnt']).reset_index()\n",
    "    res_df = df_temp.groupby(['user_id'],as_index=False).agg({'day':['max','min','std'],'cnt':['count','sum','max','var','mean']})\n",
    "    res_df.columns = ['user_id', name+'_day_max',name+'_day_min',name+'_day_std',name+'_cnt',name+'_sum',name+'_max',name+'var',name+'mean']\n",
    "    \n",
    "    res_df[name+'_last_cnt'] = df_temp.groupby(['user_id'], as_index=False).apply(lambda x:getCntOfOneDay(x))\n",
    "    res_df[name+'_2_cnt'] = df_temp.groupby(['user_id'], as_index=False).apply(lambda x:getCntOfSomeDay(x, 2))\n",
    "    res_df[name+'_2_arg_cnt'] = res_df[name+'_2_cnt'] / 2\n",
    "    res_df[name+'_3_cnt'] = df_temp.groupby(['user_id'], as_index=False).apply(lambda x:getCntOfSomeDay(x, 3))\n",
    "    res_df[name+'_3_arg_cnt'] = res_df[name+'_3_cnt'] / 3\n",
    "    res_df[name+'_week_cnt'] = df_temp.groupby(['user_id'], as_index=False).apply(lambda x:getCntOfSomeDay(x))\n",
    "    res_df[name+'_week_arg_cnt'] = res_df[name+'_week_cnt'] / 7\n",
    "    \n",
    "    temp = data.groupby(['user_id','day','page'],as_index=False).apply(lambda x:x.shape[0]).unstack().reset_index().fillna(0)\n",
    "    res_df['page_0_1_cnt'] = temp.groupby(['user_id']).apply(lambda x:getCntOfSomeDayWithCol(x,1,0))\n",
    "    res_df['page_0_3_cnt'] = temp.groupby(['user_id']).apply(lambda x:getCntOfSomeDayWithCol(x,3,0))\n",
    "    res_df['page_0_3_arg_cnt'] = res_df['page_0_3_cnt'] / 3\n",
    "    res_df['page_0_7_cnt'] = temp.groupby(['user_id']).apply(lambda x:getCntOfSomeDayWithCol(x,7,0))\n",
    "    res_df['page_0_7_arg_cnt'] = res_df['page_0_7_cnt'] / 7\n",
    "    \n",
    "    res_df['page_1_1_cnt'] = temp.groupby(['user_id']).apply(lambda x:getCntOfSomeDayWithCol(x,1,1))\n",
    "    res_df['page_1_3_cnt'] = temp.groupby(['user_id']).apply(lambda x:getCntOfSomeDayWithCol(x,3,1))\n",
    "    res_df['page_1_3_arg_cnt'] = res_df['page_1_3_cnt'] / 3\n",
    "    res_df['page_1_7_cnt'] = temp.groupby(['user_id']).apply(lambda x:getCntOfSomeDayWithCol(x,7,1))\n",
    "    res_df['page_1_7_arg_cnt'] = res_df['page_1_7_cnt'] / 7\n",
    "    \n",
    "    res_df['page_2_1_cnt'] = temp.groupby(['user_id']).apply(lambda x:getCntOfSomeDayWithCol(x,1,2))\n",
    "    res_df['page_2_3_cnt'] = temp.groupby(['user_id']).apply(lambda x:getCntOfSomeDayWithCol(x,3,2))\n",
    "    res_df['page_2_3_arg_cnt'] = res_df['page_2_3_cnt'] / 3\n",
    "    res_df['page_2_7_cnt'] = temp.groupby(['user_id']).apply(lambda x:getCntOfSomeDayWithCol(x,7,2))\n",
    "    res_df['page_2_7_arg_cnt'] = res_df['page_2_7_cnt'] / 7\n",
    "    \n",
    "    res_df['page_3_1_cnt'] = temp.groupby(['user_id']).apply(lambda x:getCntOfSomeDayWithCol(x,1,3))\n",
    "    res_df['page_3_3_cnt'] = temp.groupby(['user_id']).apply(lambda x:getCntOfSomeDayWithCol(x,3,3))\n",
    "    res_df['page_3_3_arg_cnt'] = res_df['page_3_3_cnt'] / 3\n",
    "    res_df['page_3_7_cnt'] = temp.groupby(['user_id']).apply(lambda x:getCntOfSomeDayWithCol(x,7,3))\n",
    "    res_df['page_3_7_arg_cnt'] = res_df['page_3_7_cnt'] / 7\n",
    "    \n",
    "    res_df['page_4_1_cnt'] = temp.groupby(['user_id']).apply(lambda x:getCntOfSomeDayWithCol(x,1,4))\n",
    "    res_df['page_4_3_cnt'] = temp.groupby(['user_id']).apply(lambda x:getCntOfSomeDayWithCol(x,3,4))\n",
    "    res_df['page_4_3_arg_cnt'] = res_df['page_4_3_cnt'] / 3\n",
    "    res_df['page_4_7_cnt'] = temp.groupby(['user_id']).apply(lambda x:getCntOfSomeDayWithCol(x,7,4))\n",
    "    res_df['page_4_7_arg_cnt'] = res_df['page_4_7_cnt'] / 7\n",
    "    \n",
    "    page = data.groupby(['user_id','page'],as_index=False).apply(lambda x:x.shape[0]).unstack().reset_index().fillna(0)\n",
    "    res_df['page_sum'] = page[0]+page[1]+page[2]+page[3]+page[4]\n",
    "    res_df['page_0_sigle'] = page[0] / res_df['page_sum']\n",
    "    res_df['page_1_sigle'] = page[1] / res_df['page_sum']\n",
    "    res_df['page_2_sigle'] = page[2] / res_df['page_sum']\n",
    "    res_df['page_3_sigle'] = page[3] / res_df['page_sum']\n",
    "    res_df['page_4_sigle'] = page[4] / res_df['page_sum']\n",
    "    res_df[['page_0','page_1','page_2','page_3','page_4']] = page[[0,1,2,3,4]]\n",
    "    \n",
    "    temp = data.groupby(['user_id','day','action_type'],as_index=False).apply(lambda x:x.shape[0]).unstack().reset_index().fillna(0)\n",
    "    res_df['action_type_0_1_cnt'] = temp.groupby(['user_id']).apply(lambda x:getCntOfSomeDayWithCol(x,1,0))\n",
    "    res_df['action_type_0_3_cnt'] = temp.groupby(['user_id']).apply(lambda x:getCntOfSomeDayWithCol(x,3,0))\n",
    "    res_df['action_type_0_3_arg_cnt'] = res_df['action_type_0_3_cnt'] / 3\n",
    "    res_df['action_type_0_7_cnt'] = temp.groupby(['user_id']).apply(lambda x:getCntOfSomeDayWithCol(x,7,0))\n",
    "    res_df['action_type_0_7_arg_cnt'] = res_df['action_type_0_7_cnt'] / 7\n",
    "    \n",
    "    res_df['action_type_1_1_cnt'] = temp.groupby(['user_id']).apply(lambda x:getCntOfSomeDayWithCol(x,1,1))\n",
    "    res_df['action_type_1_3_cnt'] = temp.groupby(['user_id']).apply(lambda x:getCntOfSomeDayWithCol(x,3,1))\n",
    "    res_df['action_type_1_3_arg_cnt'] = res_df['action_type_1_3_cnt'] / 3\n",
    "    res_df['action_type_1_7_cnt'] = temp.groupby(['user_id']).apply(lambda x:getCntOfSomeDayWithCol(x,7,1))\n",
    "    res_df['action_type_1_7_arg_cnt'] = res_df['action_type_1_7_cnt'] / 7\n",
    "    \n",
    "    res_df['action_type_2_1_cnt'] = temp.groupby(['user_id']).apply(lambda x:getCntOfSomeDayWithCol(x,1,2))\n",
    "    res_df['action_type_2_3_cnt'] = temp.groupby(['user_id']).apply(lambda x:getCntOfSomeDayWithCol(x,3,2))\n",
    "    res_df['action_type_2_3_arg_cnt'] = res_df['action_type_2_3_cnt'] / 3\n",
    "    res_df['action_type_2_7_cnt'] = temp.groupby(['user_id']).apply(lambda x:getCntOfSomeDayWithCol(x,7,2))\n",
    "    res_df['action_type_2_7_arg_cnt'] = res_df['action_type_2_7_cnt'] / 7\n",
    "    \n",
    "    res_df['action_type_3_1_cnt'] = temp.groupby(['user_id']).apply(lambda x:getCntOfSomeDayWithCol(x,1,3))\n",
    "    res_df['action_type_3_3_cnt'] = temp.groupby(['user_id']).apply(lambda x:getCntOfSomeDayWithCol(x,3,3))\n",
    "    res_df['action_type_3_3_arg_cnt'] = res_df['action_type_3_3_cnt'] / 3\n",
    "    res_df['action_type_3_7_cnt'] = temp.groupby(['user_id']).apply(lambda x:getCntOfSomeDayWithCol(x,7,3))\n",
    "    res_df['action_type_3_7_arg_cnt'] = res_df['action_type_3_7_cnt'] / 7\n",
    "    \n",
    "    res_df['action_type_4_1_cnt'] = temp.groupby(['user_id']).apply(lambda x:getCntOfSomeDayWithCol(x,1,4))\n",
    "    res_df['action_type_4_3_cnt'] = temp.groupby(['user_id']).apply(lambda x:getCntOfSomeDayWithCol(x,3,4))\n",
    "    res_df['action_type_4_3_arg_cnt'] = res_df['action_type_4_3_cnt'] / 3\n",
    "    res_df['action_type_4_7_cnt'] = temp.groupby(['user_id']).apply(lambda x:getCntOfSomeDayWithCol(x,7,4))\n",
    "    res_df['action_type_4_7_arg_cnt'] = res_df['action_type_4_7_cnt'] / 7\n",
    "    \n",
    "    res_df['action_type_5_1_cnt'] = temp.groupby(['user_id']).apply(lambda x:getCntOfSomeDayWithCol(x,1,5))\n",
    "    res_df['action_type_5_3_cnt'] = temp.groupby(['user_id']).apply(lambda x:getCntOfSomeDayWithCol(x,3,5))\n",
    "    res_df['action_type_5_3_arg_cnt'] = res_df['action_type_5_3_cnt'] / 3\n",
    "    res_df['action_type_5_7_cnt'] = temp.groupby(['user_id']).apply(lambda x:getCntOfSomeDayWithCol(x,7,5))\n",
    "    res_df['action_type_5_7_arg_cnt'] = res_df['action_type_5_7_cnt'] / 7\n",
    "    \n",
    "    action_type = data.groupby(['user_id','action_type'],as_index=False).apply(lambda x:x.shape[0]).unstack().reset_index()\n",
    "    res_df['action_type_sum'] = action_type[0]+action_type[1]+action_type[2]+action_type[3]+action_type[4]+action_type[5]\n",
    "    res_df['action_type_0_sigle'] = action_type[0] / res_df['action_type_sum']\n",
    "    res_df['action_type_1_sigle'] = action_type[1] / res_df['action_type_sum']\n",
    "    res_df['action_type_2_sigle'] = action_type[2] / res_df['action_type_sum']\n",
    "    res_df['action_type_3_sigle'] = action_type[3] / res_df['action_type_sum']\n",
    "    res_df['action_type_4_sigle'] = action_type[4] / res_df['action_type_sum']\n",
    "    res_df['action_type_5_sigle'] = action_type[5] / res_df['action_type_sum']\n",
    "    res_df[['action_type_0','action_type_1','action_type_2','action_type_3','action_type_4','action_type_5']] = action_type[[0,1,2,3,4,5]]\n",
    "    \n",
    "    res_df['is_author'] = res_df['user_id'].apply(lambda x: 1 if x in authors else 0)\n",
    "    return res_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 通过video 、 act 、 register 、 lauch来构造特征\n",
    "def constructDataFeature(data_url):\n",
    "    train_login = pd.read_csv(data_url+'train_login.csv')\n",
    "    train_act = pd.read_csv(data_url+'train_act.csv')\n",
    "    train_video = pd.read_csv(data_url+'train_video.csv')\n",
    "    \n",
    "    # register data\n",
    "    train_user = pd.read_csv(data_url+'train_users.csv')\n",
    "    feature = train_user\n",
    "    max_day = max(feature['register_day'])\n",
    "    feature['register_day'] = max_day - feature.register_day  # day改成时间窗口截点距离\n",
    "    \n",
    "    # login data\n",
    "    train_login_feas = getCountFeature(train_login, 'login')\n",
    "    feature = pd.merge(feature, train_login_feas, on='user_id', how='left')\n",
    "    \n",
    "    # video data\n",
    "    train_video_feas = getCountFeature(train_video, 'video')\n",
    "    feature = pd.merge(feature, train_video_feas, on='user_id', how='left')\n",
    "    \n",
    "    # act data\n",
    "    train_act_feas = getCountFeatureAboutAct(train_act, 'act')\n",
    "    feature = pd.merge(feature, train_act_feas, on='user_id', how='left')\n",
    "    \n",
    "    return feature.fillna(0)\n",
    "\n",
    "# 通过TEST未来几天内的活跃用户来给Train集标签\n",
    "def getTrainLabel(data_url, data):\n",
    "    # get activity label of train from test_dataset\n",
    "    train_label = []\n",
    "    activity_users = getActivityUsers(data_url)\n",
    "    for u in data['user_id']:\n",
    "        if u in activity_users:\n",
    "            train_label.append(1)\n",
    "        else:\n",
    "            train_label.append(0)\n",
    "    data['label'] = train_label\n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getDataProgram():\n",
    "    print(\"----------------构造训练集-------------------\")\n",
    "    \n",
    "    data_url = '../Data/data1/'\n",
    "    data1 = constructDataFeature(data_url)\n",
    "    data1 = getTrainLabel(data_url, data1)\n",
    "    print(\"---------第一组数据集处理完成----------------\")\n",
    "    data1.to_csv(data_url+'data1.csv',index=False)\n",
    "    \n",
    "    data_url = '../Data/data2/'\n",
    "    data2 = constructDataFeature(data_url)\n",
    "    data2 = getTrainLabel(data_url, data2)\n",
    "    print(\"---------第二组数据集处理完成----------------\")\n",
    "    data2.to_csv(data_url+'data2.csv',index=False)\n",
    "    \n",
    "    data_url = '../Data/data3/'\n",
    "    data3 = constructDataFeature(data_url)\n",
    "    print(\"---------第三组数据集处理完成----------------\")\n",
    "    data3.to_csv(data_url+'data3.csv',index=False)\n",
    "    \n",
    "    print(\"--------------------END----------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------构造训练集-------------------\n",
      "---------第一组数据集处理完成----------------\n",
      "---------第二组数据集处理完成----------------\n",
      "---------第三组数据集处理完成----------------\n",
      "--------------------END----------------------\n"
     ]
    }
   ],
   "source": [
    "getDataProgram()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练模型并进行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data1_in = pd.read_csv('../Data/data1/data1.csv')\n",
    "data2_in = pd.read_csv('../Data/data2/data2.csv')\n",
    "data3_in = pd.read_csv('../Data/data3/data3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 列举所有的columns\n",
    "for i in range(1,26):\n",
    "    print (list(data1_in.columns)[(i-1)*5: i*5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 手动标定不需要的cols\n",
    "drop_cols = ['login_sum','login_max','loginvar','loginmean','login_3_cnt','login_2_cnt','login_week_cnt','device_map'] + ['page_sum','page_0_sigle','page_1_sigle','page_2_sigle','page_3_sigle','page_4_sigle',\n",
    "                 'action_type_sum','action_type_0_sigle','action_type_1_sigle','action_type_2_sigle',\n",
    "                 'action_type_3_sigle','action_type_4_sigle','action_type_5_sigle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 特征选择之后的cols， 目前不起作用\n",
    "select_cols = ['user_id','label'] + ['login_day_min', 'device_type', 'login_week_arg_cnt', 'register_type',\n",
    "       'act_last_cnt', 'login_day_std', 'action_type_0', 'act_week_cnt',\n",
    "       'page_1', 'act_3_cnt', 'login_cnt', 'page_0', 'act_day_std', 'actmean',\n",
    "       'page_2', 'login_3_arg_cnt', 'register_day', 'act_sum', 'act_cnt',\n",
    "       'action_type_1', 'action_type_2', 'act_day_min', 'actvar',\n",
    "       'act_day_max', 'act_max', 'page_3', 'video_last_cnt', 'action_type_3',\n",
    "       'page_4', 'video_3_cnt', 'videomean', 'video_sum', 'is_author',\n",
    "       'page_3_7_cnt', 'action_type_1_7_cnt', 'video_day_min',\n",
    "       'video_week_cnt', 'action_type_0_7_cnt', 'video_day_max', 'video_cnt',\n",
    "       'videovar', 'action_type_2_7_cnt', 'page_3_3_cnt', 'video_day_std',\n",
    "       'action_type_0_1_cnt', 'action_type_0_3_cnt', 'action_type_5',\n",
    "       'action_type_1_3_cnt', 'page_0_1_cnt', 'video_max', 'page_0_7_cnt',\n",
    "       'page_0_3_cnt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# device_type 目前感觉挺有操作空间的，但是还没找到合适的处理方式\n",
    "# map不如直接丢进去\n",
    "def mapDeviceType(thread_value=0.5):\n",
    "    con_data = pd.concat([data1_in, data2_in])\n",
    "    index = con_data['label'].groupby(con_data[\"device_type\"]).mean().index\n",
    "    values = con_data['label'].groupby(con_data[\"device_type\"]).mean().get_values()\n",
    "    return index[values>thread_value]\n",
    "\n",
    "good_index = mapDeviceType()\n",
    "\n",
    "data1_in['device_map'] = data1_in['device_type'].apply(lambda x: int(x in good_index))\n",
    "data2_in['device_map'] = data1_in['device_type'].apply(lambda x: int(x in good_index))\n",
    "data3_in['device_map'] = data1_in['device_type'].apply(lambda x: int(x in good_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data1 = data1_in[[c for c in data1_in.columns if c not in drop_cols and c in select_cols]]\n",
    "# data2 = data2_in[[c for c in data2_in.columns if c not in drop_cols and c in select_cols]]\n",
    "# data3 = data3_in[[c for c in data3_in.columns if c not in drop_cols and c in select_cols]]\n",
    "\n",
    "data1 = data1_in[[c for c in data1_in.columns if c not in drop_cols]]\n",
    "data2 = data2_in[[c for c in data2_in.columns if c not in drop_cols]]\n",
    "data3 = data3_in[[c for c in data3_in.columns if c not in drop_cols]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22342, 110)\n",
      "(26571, 110)\n",
      "(51709, 109)\n"
     ]
    }
   ],
   "source": [
    "print (data1.shape)\n",
    "print (data2.shape)\n",
    "print (data3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 目前线上的参数，调过\n",
    "LGBM = lgb.LGBMClassifier(  max_depth=6,\n",
    "                            n_estimators = 280,\n",
    "                            learning_rate =0.05,     \n",
    "                            objective = 'binary',\n",
    "                            num_leaves=25,\n",
    "                            boosting_type = 'dart',\n",
    "                            feature_fraction=0.5,\n",
    "                            lambda_l1=1,\n",
    "                            lambda_l2=0.5,\n",
    "                            subsample=0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 题目规定线下 F1计算方法\n",
    "def sroceF1(pred, real):\n",
    "    M = set(pred)\n",
    "    N = set(real)\n",
    "    Precision = len(M.intersection(N))/len(M)\n",
    "    Recall = len(M.intersection(N))/len(N)\n",
    "    F1 = 2*Precision*Recall/(Precision+Recall)\n",
    "\n",
    "    print(\"Precision=\",Precision,\"| Recall=\",Recall)\n",
    "    print(\"F1=\",F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 训练模型，做预测\n",
    "def buildModelAndPredict(isOnLine=True, isTest=False, yuzhi=0.4, model=lgb.LGBMClassifier(  max_depth=3,\n",
    "                                                                    n_estimators = 120,\n",
    "                                                                    learning_rate = 0.05,     \n",
    "                                                                    objective = 'binary',\n",
    "                                                                    subsample = 0.7,\n",
    "                                                                    colsample_bytree = 0.74,\n",
    "                                                                    num_leaves = 8)\n",
    "                        ):\n",
    "    # 线上预测\n",
    "    # @return: 返回活跃用户\n",
    "    if (isOnLine):\n",
    "        train = pd.concat([data1, data2])\n",
    "        test = data3.copy()\n",
    "        train.pop('user_id')\n",
    "        label = train.pop('label')\n",
    "        \n",
    "        model.fit(train, label)\n",
    "        user_list = test.pop('user_id')\n",
    "        user_df = pd.DataFrame(user_list)\n",
    "        user_df['pre_act'] = model.predict_proba(test)[:,1]\n",
    "        return user_df[user_df.pre_act>yuzhi]['user_id']\n",
    "\n",
    "    # 线下训练调试\n",
    "    else: \n",
    "        train = data1.copy()\n",
    "        test = data2.copy()\n",
    "        train.pop('user_id')\n",
    "        train_df_label = train.pop('label')\n",
    "        train_df = train\n",
    "        \n",
    "        real_user = test[test.label==1]['user_id']\n",
    "        user_list = test.pop('user_id')\n",
    "        test.pop('label')\n",
    "        test_df = test\n",
    "        \n",
    "        user_df = pd.DataFrame(user_list)\n",
    "        model.fit(train_df, train_df_label)\n",
    "        user_df['pre_act'] = model.predict_proba(test_df)[:,1]\n",
    "        \n",
    "        user_pre = user_df[user_df.pre_act>yuzhi]['user_id']\n",
    "        sroceF1(user_pre, real_user)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 遍历阈值，结合用户个数和F1值取阈值\n",
    "for i in np.arange(0.4, 0.45, 0.001):\n",
    "    print (i)\n",
    "    user_pre = buildModelAndPredict(isOnLine=False, isTest=False, yuzhi=i, model=LGBM)\n",
    "    user_pre = buildModelAndPredict(isOnLine=True, isTest=False, yuzhi=i, model=LGBM)\n",
    "    print (len(user_pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_pre = buildModelAndPredict(isOnLine=True, isTest=False, yuzhi=0.4, model=LGBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24353"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(user_pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 结果数据提交"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_pre.to_csv('../Output/108_8029_23973_42.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
