{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#==========================去除共线性特征16day b榜单==========================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_diff_from_ls(x):\n",
    "    x.sort()\n",
    "    return list(np.diff(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#加载数据\n",
    "def load_data(base_path):\n",
    "    user_register_log_df = pd.read_csv(base_path+'/user_register_log.txt',sep='\\t',header=None,names=['user_id','register_day','register_type','device_type'])\n",
    "    app_launch_log_df = pd.read_csv(base_path+'/app_launch_log.txt',sep='\\t',header=None,names=['user_id','day'])\n",
    "    video_create_log_df = pd.read_csv(base_path+'/video_create_log.txt',sep='\\t',header=None,names=['user_id','day'])\n",
    "    user_activity_log_df = pd.read_csv(base_path+'/user_activity_log.txt',sep='\\t',header=None,names = ['user_id','day','page','video_id','author_id','action_type'])\n",
    "    return user_register_log_df,app_launch_log_df,video_create_log_df,user_activity_log_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#注册特征\n",
    "def get_register_feature(start_day,end_day):\n",
    "    register = user_register_log_df[user_register_log_df.register_day<=end_day].copy()\n",
    "    register['r_day_diff'] = register.register_day.apply(lambda x: end_day-x)\n",
    "    return register\n",
    "\n",
    "#获取label\n",
    "def get_label(start_day,end_day):\n",
    "    app_temp_df=app_launch_log_df[(app_launch_log_df.day<=end_day) & (app_launch_log_df.day>=start_day)][['user_id']].drop_duplicates()\n",
    "    video_temp_df=video_create_log_df[(video_create_log_df.day<=end_day) & (video_create_log_df.day>=start_day)][['user_id']].drop_duplicates()\n",
    "    action_temp_df=user_activity_log_df[(user_activity_log_df.day<=end_day) & (user_activity_log_df.day>=start_day)][['user_id']].drop_duplicates()\n",
    "    label=pd.concat([app_temp_df,video_temp_df,action_temp_df],axis=0).drop_duplicates()\n",
    "    label['label']=1\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#登录 cnt 特征\n",
    "def get_launch_cnt_feature1(start_day,end_day):\n",
    "    launch = app_launch_log_df[['user_id']].drop_duplicates()\n",
    "    df = app_launch_log_df[(app_launch_log_df.day>=start_day)&(app_launch_log_df.day<=end_day)][['user_id','day']]\n",
    "    df.day = end_day - df.day\n",
    "    for day in [1,3,7]:\n",
    "        launch_temp = df[df.day<day][['user_id']]\n",
    "        launch_temp['l_cnt_sum_in_'+str(day)] = 1\n",
    "        launch_temp = launch_temp.groupby(['user_id']).agg('sum').reset_index()\n",
    "#         if day!=1:\n",
    "#             launch_temp['l_cnt_mean_in_'+str(day)] = launch_temp['l_cnt_sum_in_'+str(day)] / day\n",
    "        launch=pd.merge(launch,launch_temp,on=['user_id'],how='left').fillna(0)\n",
    "    launch['l_cnt_weight_sum']=0\n",
    "    for day in [1,3,7]:\n",
    "        launch['l_cnt_weight_sum']+=launch['l_cnt_sum_in_'+str(day)]*(8-day)\n",
    "    return launch.fillna(0)\n",
    "\n",
    "#登录 日cnt 特征(用户每天只登陆一次 无意义)\n",
    "def get_launch_cnt_feature2(start_day,end_day):\n",
    "    launch = app_launch_log_df[['user_id']].drop_duplicates()\n",
    "    df = app_launch_log_df[(app_launch_log_df.day>=start_day)&(app_launch_log_df.day<=end_day)][['user_id','day']]\n",
    "    df['cnt'] = 1\n",
    "    df = df.groupby(['user_id','day']).agg('sum').reset_index()\n",
    "    launch_temp = df.groupby(['user_id']).aggregate(lambda x: list(x)).reset_index()\n",
    "    launch_temp['l_cnt_count'] = launch_temp.cnt.apply(lambda x: len(x))\n",
    "#     launch_temp['l_cnt_sum'] = launch_temp.cnt.apply(lambda x: sum(x))\n",
    "#     launch_temp['l_cnt_mean'] = launch_temp.cnt.apply(lambda x: np.mean(x))\n",
    "#     launch_temp['l_cnt_max'] = launch_temp.cnt.apply(lambda x: max(x))\n",
    "    launch_temp['l_cnt_var'] = launch_temp.cnt.apply(lambda x: pd.Series(x).var())\n",
    "    launch = pd.merge(launch,launch_temp.drop(['day','cnt'],axis=1),on=['user_id'],how='left')\n",
    "    return launch.fillna(0)\n",
    "\n",
    "#登录 日期 特征\n",
    "def get_launch_day_feature1(start_day,end_day):\n",
    "    launch = app_launch_log_df[['user_id']].drop_duplicates()\n",
    "    df = app_launch_log_df[(app_launch_log_df.day>=start_day)&(app_launch_log_df.day<=end_day)][['user_id','day']]\n",
    "    df.day = end_day - df.day\n",
    "    launch_temp = df.groupby(['user_id']).aggregate(lambda x: list(x)).reset_index()\n",
    "    launch_temp['l_day_max'] = launch_temp.day.apply(lambda x: max(x))\n",
    "    launch_temp['l_day_min'] = launch_temp.day.apply(lambda x: min(x))\n",
    "    launch_temp['l_day_range'] = launch_temp.day.apply(lambda x: max(x)-min(x))\n",
    "    launch_temp['l_day_std'] = launch_temp.day.apply(lambda x: pd.Series(x).std())\n",
    "    launch = pd.merge(launch,launch_temp.drop(['day'],axis=1),on=['user_id'],how='left')\n",
    "    return launch.fillna(-1) #-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#拍摄 cnt 特征\n",
    "def get_video_cnt_feature1(start_day,end_day):\n",
    "    video = video_create_log_df[['user_id']].drop_duplicates()\n",
    "    df = video_create_log_df[(video_create_log_df.day>=start_day)&(video_create_log_df.day<=end_day)][['user_id','day']]\n",
    "    df.day = end_day - df.day\n",
    "    for day in [1,3,7]:\n",
    "        video_temp = df[df.day<day][['user_id']]\n",
    "        video_temp['v_cnt_sum_in_'+str(day)] = 1\n",
    "        video_temp = video_temp.groupby(['user_id']).agg('sum').reset_index()\n",
    "#         if day!=1:\n",
    "#             video_temp['v_cnt_mean_in_'+str(day)] = video_temp['v_cnt_sum_in_'+str(day)] / day\n",
    "        video=pd.merge(video,video_temp,on=['user_id'],how='left').fillna(0)\n",
    "    video['v_cnt_weight_sum']=0\n",
    "    for day in [1,3,7]:\n",
    "        video['v_cnt_weight_sum']+=video['v_cnt_sum_in_'+str(day)]*(8-day)\n",
    "    return video.fillna(0)\n",
    "\n",
    "#拍摄 日cnt 特征\n",
    "def get_video_cnt_feature2(start_day,end_day):\n",
    "    video = video_create_log_df[['user_id']].drop_duplicates()\n",
    "    df = video_create_log_df[(video_create_log_df.day>=start_day)&(video_create_log_df.day<=end_day)][['user_id','day']]\n",
    "    df['cnt'] = 1\n",
    "    df = df.groupby(['user_id','day']).agg('sum').reset_index()\n",
    "    video_temp = df.groupby(['user_id']).aggregate(lambda x: list(x)).reset_index()\n",
    "#     video_temp['v_cnt_count'] = video_temp.cnt.apply(lambda x: len(x))\n",
    "    video_temp['v_cnt_sum'] = video_temp.cnt.apply(lambda x: sum(x))\n",
    "    video_temp['v_cnt_mean'] = video_temp.cnt.apply(lambda x: np.mean(x))\n",
    "#     video_temp['v_cnt_max'] = video_temp.cnt.apply(lambda x: max(x))\n",
    "#     video_temp['v_cnt_var'] = video_temp.cnt.apply(lambda x: pd.Series(x).var())\n",
    "    video = pd.merge(video,video_temp.drop(['day','cnt'],axis=1),on=['user_id'],how='left')\n",
    "    return video.fillna(0)\n",
    "\n",
    "#拍摄 日期 特征\n",
    "def get_video_day_feature1(start_day,end_day):\n",
    "    video = video_create_log_df[['user_id']].drop_duplicates()\n",
    "    df = video_create_log_df[(video_create_log_df.day>=start_day)&(video_create_log_df.day<=end_day)][['user_id','day']]\n",
    "    df.day = end_day - df.day\n",
    "    video_temp = df.groupby(['user_id']).aggregate(lambda x: list(x)).reset_index()\n",
    "    video_temp['v_day_max'] = video_temp.day.apply(lambda x: max(x))\n",
    "    video_temp['v_day_min'] = video_temp.day.apply(lambda x: min(x))\n",
    "#     video_temp['v_day_range'] = video_temp.day.apply(lambda x: max(x)-min(x))\n",
    "    video_temp['v_day_std'] = video_temp.day.apply(lambda x: pd.Series(x).std())\n",
    "    video = pd.merge(video,video_temp.drop(['day'],axis=1),on=['user_id'],how='left')\n",
    "    return video.fillna(-1) #-1\n",
    "\n",
    "# 拍摄 cnt差分 特征\n",
    "def get_video_cnt_diff_feature(start_day, end_day):\n",
    "    video = video_create_log_df[['user_id']].drop_duplicates()\n",
    "    df = video_create_log_df[(video_create_log_df.day >= start_day) & (video_create_log_df.day <= end_day)][\n",
    "        ['user_id', 'day']]\n",
    "    df['cnt'] = 1\n",
    "    df = df.groupby(['user_id', 'day']).agg('sum').reset_index()\n",
    "    video_temp = df.groupby(['user_id']).aggregate(lambda x: list(x)).reset_index()\n",
    "    video_temp.cnt = video_temp.cnt.apply(lambda x: np.diff(x))\n",
    "#     video_temp['v_cnt_diff_max'] = video_temp.cnt.apply(lambda x: max(x) if len(x) != 0 else np.nan)\n",
    "    video_temp['v_cnt_diff_min'] = video_temp.cnt.apply(lambda x: min(x) if len(x) != 0 else np.nan)\n",
    "    video_temp['v_cnt_diff_mean'] = video_temp.cnt.apply(lambda x: np.mean(x) if len(x) != 0 else np.nan)\n",
    "    video_temp['v_cnt_diff_std'] = video_temp.cnt.apply(lambda x: np.std(x) if len(x) != 0 else np.nan)\n",
    "#     video_temp['v_cnt_diff_skew'] = video_temp.cnt.apply(lambda x: pd.Series(x).skew())\n",
    "    video_temp['v_cnt_diff_kurt'] = video_temp.cnt.apply(lambda x: pd.Series(x).kurt())\n",
    "    video = pd.merge(video, video_temp.drop(['day', 'cnt'], axis=1), on=['user_id'], how='left')\n",
    "    return video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#行为 cnt 特征\n",
    "def get_action_cnt_feature1(start_day,end_day):\n",
    "    action = user_activity_log_df[['user_id']].drop_duplicates()\n",
    "    df = user_activity_log_df[(user_activity_log_df.day>=start_day)&(user_activity_log_df.day<=end_day)][['user_id','day']]\n",
    "    df.day = end_day - df.day\n",
    "    for day in [1,3,7]:\n",
    "        action_temp = df[df.day<day][['user_id']]\n",
    "        action_temp['a_cnt_sum_in_'+str(day)] = 1\n",
    "        action_temp = action_temp.groupby(['user_id']).agg('sum').reset_index()\n",
    "#         if day!=1:\n",
    "#             action_temp['a_cnt_mean_in_'+str(day)] = action_temp['a_cnt_sum_in_'+str(day)] / day\n",
    "        action=pd.merge(action,action_temp,on=['user_id'],how='left').fillna(0)\n",
    "    action['a_cnt_weight_sum']=0\n",
    "    for day in [1,3,7]:\n",
    "        action['a_cnt_weight_sum']+=action['a_cnt_sum_in_'+str(day)]*(8-day)\n",
    "    return action.fillna(0)\n",
    "\n",
    "#行为 日cnt 特征\n",
    "def get_action_cnt_feature2(start_day,end_day):\n",
    "    action = user_activity_log_df[['user_id']].drop_duplicates()\n",
    "    df = user_activity_log_df[(user_activity_log_df.day>=start_day)&(user_activity_log_df.day<=end_day)][['user_id','day']]\n",
    "    df['cnt'] = 1\n",
    "    df = df.groupby(['user_id','day']).agg('sum').reset_index()\n",
    "    action_temp = df.groupby(['user_id']).aggregate(lambda x: list(x)).reset_index()\n",
    "    action_temp['a_cnt_count'] = action_temp.cnt.apply(lambda x: len(x))\n",
    "    action_temp['a_cnt_sum'] = action_temp.cnt.apply(lambda x: sum(x))\n",
    "    action_temp['a_cnt_mean'] = action_temp.cnt.apply(lambda x: np.mean(x))\n",
    "    action_temp['a_cnt_max'] = action_temp.cnt.apply(lambda x: max(x))\n",
    "    action_temp['a_cnt_var'] = action_temp.cnt.apply(lambda x: pd.Series(x).var())\n",
    "    action = pd.merge(action,action_temp.drop(['day','cnt'],axis=1),on=['user_id'],how='left')\n",
    "    return action.fillna(0)\n",
    "\n",
    "#行为 日期 特征\n",
    "def get_action_day_feature1(start_day,end_day):\n",
    "    action = user_activity_log_df[['user_id']].drop_duplicates()\n",
    "    df = user_activity_log_df[(user_activity_log_df.day>=start_day)&(user_activity_log_df.day<=end_day)][['user_id','day']]\n",
    "    df.day = end_day - df.day\n",
    "    action_temp = df.groupby(['user_id']).aggregate(lambda x: list(x)).reset_index()\n",
    "    action_temp['a_day_max'] = action_temp.day.apply(lambda x: max(x))\n",
    "    action_temp['a_day_min'] = action_temp.day.apply(lambda x: min(x))\n",
    "    action_temp['a_day_range'] = action_temp.day.apply(lambda x: max(x)-min(x))\n",
    "    action_temp['a_day_std'] = action_temp.day.apply(lambda x: pd.Series(x).std())\n",
    "    action = pd.merge(action,action_temp.drop(['day'],axis=1),on=['user_id'],how='left')\n",
    "    return action.fillna(-1) #-1\n",
    "\n",
    "# #行为 作者 特征\n",
    "# def get_action_author_feature(start_day,end_day):\n",
    "#     action = user_activity_log_df[['user_id']].drop_duplicates()\n",
    "#     df = user_activity_log_df[(user_activity_log_df.day>=start_day)&(user_activity_log_df.day<=end_day)][['user_id','author_id']]\n",
    "#     authors = set(df['author_id'])\n",
    "#     action['is_author'] = action.user_id.apply(lambda x: 1 if x in authors else 0)\n",
    "#     return action\n",
    "\n",
    "# 行为 cnt差分 特征\n",
    "def get_action_cnt_diff_feature(start_day, end_day):\n",
    "    action = user_activity_log_df[['user_id']].drop_duplicates()\n",
    "    df = user_activity_log_df[(user_activity_log_df.day >= start_day) & (user_activity_log_df.day <= end_day)][\n",
    "        ['user_id', 'day']]\n",
    "    df['cnt'] = 1\n",
    "    df = df.groupby(['user_id', 'day']).agg('sum').reset_index()\n",
    "    action_temp = df.groupby(['user_id']).aggregate(lambda x: list(x)).reset_index()\n",
    "    action_temp.cnt = action_temp.cnt.apply(lambda x: np.diff(x))\n",
    "    action_temp['a_cnt_diff_max'] = action_temp.cnt.apply(lambda x: max(x) if len(x) != 0 else np.nan)\n",
    "    action_temp['a_cnt_diff_min'] = action_temp.cnt.apply(lambda x: min(x) if len(x) != 0 else np.nan)\n",
    "    action_temp['a_cnt_diff_mean'] = action_temp.cnt.apply(lambda x: np.mean(x) if len(x) != 0 else np.nan)\n",
    "    action_temp['a_cnt_diff_std'] = action_temp.cnt.apply(lambda x: np.std(x) if len(x) != 0 else np.nan)\n",
    "    action_temp['a_cnt_diff_skew'] = action_temp.cnt.apply(lambda x: pd.Series(x).skew())\n",
    "    action_temp['a_cnt_diff_kurt'] = action_temp.cnt.apply(lambda x: pd.Series(x).kurt())\n",
    "    action = pd.merge(action, action_temp.drop(['day', 'cnt'], axis=1), on=['user_id'], how='left')\n",
    "    return action  # -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 行为 视频和作者 特征\n",
    "def get_action_video_author_feature(start_day, end_day):\n",
    "    action = user_activity_log_df[['user_id']].drop_duplicates()\n",
    "    df = user_activity_log_df[(user_activity_log_df.day >= start_day) & (user_activity_log_df.day <= end_day)][\n",
    "        ['user_id', 'day', 'video_id', 'author_id']]\n",
    "    df.day = end_day - df.day\n",
    "    for day in [1, 3, 7, end_day - start_day + 1]:\n",
    "        # 看过的不同视频数量\n",
    "        action_temp_df = df[df.day < day][['user_id', 'video_id']]\n",
    "        action_temp_df = action_temp_df.groupby(['user_id']).aggregate(lambda x: list(set(x))).reset_index()\n",
    "        action_temp_df['a_video_set_cnt_in_' + str(day)] = action_temp_df.video_id.apply(lambda x: len(x))\n",
    "        action_temp_df = action_temp_df.drop(['video_id'], axis=1)\n",
    "        action = pd.merge(action, action_temp_df, on=['user_id'], how='left')\n",
    "        # 看过的不同作者数量\n",
    "        action_temp_df = df[df.day < day][['user_id', 'author_id']]\n",
    "        action_temp_df = action_temp_df.groupby(['user_id']).aggregate(lambda x: list(set(x))).reset_index()\n",
    "        action_temp_df['a_author_set_cnt_in_' + str(day)] = action_temp_df.author_id.apply(lambda x: len(x))\n",
    "        action_temp_df = action_temp_df.drop(['author_id'], axis=1)\n",
    "        action = pd.merge(action, action_temp_df, on=['user_id'], how='left')\n",
    "    return action.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#行为page cnt 特征\n",
    "def get_action_page_feature1(start_day,end_day):\n",
    "    pages=user_activity_log_df.page.unique()\n",
    "    pages.sort()\n",
    "    action = user_activity_log_df[['user_id']].drop_duplicates()\n",
    "    df = user_activity_log_df[(user_activity_log_df.day>=start_day)&(user_activity_log_df.day<=end_day)][['user_id','day','page']]\n",
    "    df.day = end_day - df.day\n",
    "    for page in pages:\n",
    "        for day in [1,3,7,end_day-start_day+1]:\n",
    "            action_temp = df[(df.day<day)&(df.page==page)][['user_id']]\n",
    "            action_temp['a_p'+str(page)+'_cnt_sum_in_'+str(day)] = 1\n",
    "            action_temp = action_temp.groupby(['user_id']).agg('sum').reset_index()\n",
    "#             if (day!=1) and (day!=15):\n",
    "#                 action_temp['a_p'+str(page)+'_cnt_mean_in_'+str(day)] = action_temp['a_p'+str(page)+'_cnt_sum_in_'+str(day)] / day\n",
    "            action = pd.merge(action,action_temp,on=['user_id'],how='left').fillna(0)\n",
    "        action['a_p'+str(page)+'_cnt_weight_sum']=0\n",
    "        for day in [1,3,7,end_day-start_day+1]:\n",
    "            action['a_p'+str(page)+'_cnt_weight_sum']+=action['a_p'+str(page)+'_cnt_sum_in_'+str(day)]*(end_day-start_day+2-day)\n",
    "    return action.fillna(0)\n",
    "\n",
    "#行为page 占比 特征\n",
    "def get_action_page_feature2(start_day,end_day):\n",
    "    action = user_activity_log_df[['user_id']].drop_duplicates()\n",
    "    df = user_activity_log_df[(user_activity_log_df.day>=start_day)&(user_activity_log_df.day<=end_day)][['user_id','day','page']]\n",
    "    df['cnt'] = 1\n",
    "    df = df.groupby(['user_id','page']).agg(lambda x: x.shape[0]).unstack().reset_index().fillna(0)\n",
    "    action_temp=pd.DataFrame()\n",
    "    action_temp['user_id']=df['user_id']\n",
    "    df['page_cnt']=df.cnt.apply(lambda x: x.sum(),axis=1)\n",
    "    action_temp['a_p0_weight'] = df.cnt[0] / df.page_cnt\n",
    "    action_temp['a_p1_weight'] = df.cnt[1] / df.page_cnt\n",
    "    action_temp['a_p2_weight'] = df.cnt[2] / df.page_cnt\n",
    "    action_temp['a_p3_weight'] = df.cnt[3] / df.page_cnt\n",
    "    action_temp['a_p4_weight'] = df.cnt[4] / df.page_cnt\n",
    "    action=pd.merge(action,action_temp,on=['user_id'],how='left')\n",
    "    return action.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#行为type cnt 特征\n",
    "def get_action_atype_feature1(start_day,end_day):\n",
    "    atypes=user_activity_log_df.action_type.unique()\n",
    "    atypes.sort()\n",
    "    action = user_activity_log_df[['user_id']].drop_duplicates()\n",
    "    df = user_activity_log_df[(user_activity_log_df.day>=start_day)&(user_activity_log_df.day<=end_day)][['user_id','day','action_type']]\n",
    "    df.day = end_day - df.day\n",
    "    for atype in atypes:\n",
    "        for day in [1,3,7,end_day-start_day+1]:\n",
    "            action_temp = df[(df.day<day)&(df.action_type==atype)][['user_id']]\n",
    "            action_temp['a_a'+str(atype)+'_cnt_sum_in_'+str(day)] = 1\n",
    "            action_temp = action_temp.groupby(['user_id']).agg('sum').reset_index()\n",
    "#             if (day!=1) and (day!=15):\n",
    "#                 action_temp['a_a'+str(atype)+'_cnt_mean_in_'+str(day)] = action_temp['a_a'+str(atype)+'_cnt_sum_in_'+str(day)] / day\n",
    "            action = pd.merge(action,action_temp,on=['user_id'],how='left').fillna(0)\n",
    "        action['a_a'+str(atype)+'_cnt_weight_sum']=0\n",
    "        for day in [1,3,7,end_day-start_day+1]:\n",
    "            action['a_a'+str(atype)+'_cnt_weight_sum']+=action['a_a'+str(atype)+'_cnt_sum_in_'+str(day)]*(end_day-start_day+2-day)\n",
    "    return action.fillna(0)\n",
    "\n",
    "#行为type 占比 特征\n",
    "def get_action_atype_feature2(start_day,end_day):\n",
    "    action = user_activity_log_df[['user_id']].drop_duplicates()\n",
    "    df = user_activity_log_df[(user_activity_log_df.day>=start_day)&(user_activity_log_df.day<=end_day)][['user_id','day','action_type']]\n",
    "    df['cnt'] = 1\n",
    "    df = df.groupby(['user_id','action_type']).agg(lambda x: x.shape[0]).unstack().reset_index().fillna(0)\n",
    "    action_temp=pd.DataFrame()\n",
    "    action_temp['user_id']=df['user_id']\n",
    "    df['atype_cnt']=df.cnt.apply(lambda x: x.sum(),axis=1)\n",
    "    action_temp['a_a0_weight'] = df.cnt[0] / df.atype_cnt\n",
    "    action_temp['a_a1_weight'] = df.cnt[1] / df.atype_cnt\n",
    "    action_temp['a_a2_weight'] = df.cnt[2] / df.atype_cnt\n",
    "    action_temp['a_a3_weight'] = df.cnt[3] / df.atype_cnt\n",
    "    action_temp['a_a4_weight'] = df.cnt[4] / df.atype_cnt\n",
    "    action_temp['a_a5_weight'] = df.cnt[5] / df.atype_cnt\n",
    "    action=pd.merge(action,action_temp,on=['user_id'],how='left')\n",
    "    return action.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 登录 日期差分 特征\n",
    "def get_launch_day_diff_feature(start_day, end_day):\n",
    "    launch = app_launch_log_df[['user_id']].drop_duplicates()\n",
    "    df = app_launch_log_df[(app_launch_log_df.day >= start_day) & (app_launch_log_df.day <= end_day)][\n",
    "        ['user_id', 'day']]\n",
    "    launch_temp = df.groupby(['user_id']).aggregate(lambda x: list(x)).reset_index()  # 是否去重\n",
    "    launch_temp.day = launch_temp.day.apply(lambda x: get_diff_from_ls(x))\n",
    "    launch_temp['l_day_diff_max'] = launch_temp.day.apply(lambda x: max(x) if len(x) != 0 else np.nan)\n",
    "    launch_temp['l_day_diff_min'] = launch_temp.day.apply(lambda x: min(x) if len(x) != 0 else np.nan)\n",
    "    launch_temp['l_day_diff_mean'] = launch_temp.day.apply(lambda x: np.mean(x) if len(x) != 0 else np.nan)\n",
    "    launch_temp['l_day_diff_std'] = launch_temp.day.apply(lambda x: np.std(x) if len(x) != 0 else np.nan)\n",
    "    launch_temp['l_day_diff_skew'] = launch_temp.day.apply(lambda x: pd.Series(x).skew())\n",
    "    launch_temp['l_day_diff_kurt'] = launch_temp.day.apply(lambda x: pd.Series(x).kurt())\n",
    "    launch = pd.merge(launch, launch_temp.drop(['day'], axis=1), on=['user_id'], how='left')\n",
    "    return launch  # -1\n",
    "\n",
    "# 拍摄 日期差分 特征\n",
    "def get_video_day_diff_feature(start_day, end_day):\n",
    "    video = video_create_log_df[['user_id']].drop_duplicates()\n",
    "    df = video_create_log_df[(video_create_log_df.day >= start_day) & (video_create_log_df.day <= end_day)][\n",
    "        ['user_id', 'day']]\n",
    "    video_temp = df.groupby(['user_id']).aggregate(lambda x: list(x)).reset_index()  # 是否去重\n",
    "    video_temp.day = video_temp.day.apply(lambda x: get_diff_from_ls(x))\n",
    "#     video_temp['v_day_diff_max'] = video_temp.day.apply(lambda x: max(x) if len(x) != 0 else np.nan)\n",
    "#     video_temp['v_day_diff_min'] = video_temp.day.apply(lambda x: min(x) if len(x) != 0 else np.nan)\n",
    "    video_temp['v_day_diff_mean'] = video_temp.day.apply(lambda x: np.mean(x) if len(x) != 0 else np.nan)\n",
    "    video_temp['v_day_diff_std'] = video_temp.day.apply(lambda x: np.std(x) if len(x) != 0 else np.nan)\n",
    "    video_temp['v_day_diff_skew'] = video_temp.day.apply(lambda x: pd.Series(x).skew())\n",
    "    video_temp['v_day_diff_kurt'] = video_temp.day.apply(lambda x: pd.Series(x).kurt())\n",
    "    video = pd.merge(video, video_temp.drop(['day'], axis=1), on=['user_id'], how='left')\n",
    "    return video  # -1\n",
    "\n",
    "# 行为 日期差分 特征\n",
    "def get_action_day_diff_feature(start_day, end_day):\n",
    "    action = user_activity_log_df[['user_id']].drop_duplicates()\n",
    "    df = user_activity_log_df[(user_activity_log_df.day >= start_day) & (user_activity_log_df.day <= end_day)][\n",
    "        ['user_id', 'day']]\n",
    "    action_temp = df.groupby(['user_id']).aggregate(lambda x: list(x)).reset_index()  # 是否去重\n",
    "    action_temp.day = action_temp.day.apply(lambda x: get_diff_from_ls(x))\n",
    "    action_temp['a_day_diff_max'] = action_temp.day.apply(lambda x: max(x) if len(x) != 0 else np.nan)\n",
    "#     action_temp['a_day_diff_min'] = action_temp.day.apply(lambda x: min(x) if len(x) != 0 else np.nan)\n",
    "    action_temp['a_day_diff_mean'] = action_temp.day.apply(lambda x: np.mean(x) if len(x) != 0 else np.nan)\n",
    "    action_temp['a_day_diff_std'] = action_temp.day.apply(lambda x: np.std(x) if len(x) != 0 else np.nan)\n",
    "    action_temp['a_day_diff_skew'] = action_temp.day.apply(lambda x: pd.Series(x).skew())\n",
    "    action_temp['a_day_diff_kurt'] = action_temp.day.apply(lambda x: pd.Series(x).kurt())\n",
    "    action = pd.merge(action, action_temp.drop(['day'], axis=1), on=['user_id'], how='left')\n",
    "    return action  # -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 留存特征\n",
    "# 距离观测点(end_day)1天内、3天内和7天内留存率\n",
    "def get_register_retention_feature1(start_day, end_day):\n",
    "    register = user_register_log_df[user_register_log_df.register_day <= end_day][['user_id', 'register_day']]\n",
    "    retention = register.groupby(['register_day']).agg({'user_id': 'count'}).reset_index()\n",
    "    for day_cell in [3, 7]:\n",
    "        app_temp_df = app_launch_log_df[(app_launch_log_df.day <= end_day) & (app_launch_log_df.day > end_day - day_cell)][['user_id']]\n",
    "        video_temp_df = video_create_log_df[(video_create_log_df.day <= end_day) & (video_create_log_df.day > end_day - day_cell)][['user_id']]\n",
    "        action_temp_df = user_activity_log_df[(user_activity_log_df.day <= end_day) & (user_activity_log_df.day > end_day - day_cell)][['user_id']]\n",
    "        active_temp = pd.concat([app_temp_df, video_temp_df, action_temp_df], axis=0).drop_duplicates()\n",
    "        retention_temp = pd.merge(active_temp, register, on=['user_id'], how='left')\n",
    "        retention_temp = retention_temp.groupby(['register_day']).agg('count').reset_index()\n",
    "        retention_temp.rename(columns={'user_id': 'r_retention_in_' + str(day_cell)}, inplace=True)\n",
    "        retention = pd.merge(retention, retention_temp, on=['register_day'], how='left')\n",
    "        retention['r_retention_in_' + str(day_cell)] = retention['r_retention_in_' + str(day_cell)] / retention.user_id\n",
    "    retention.rename(columns={'user_id': 'r_cnt_daily'}, inplace=True)\n",
    "    return retention.fillna(0)\n",
    "\n",
    "\n",
    "# 距离观测点(end_day)1天、3天和7天留存率\n",
    "def get_register_retention_feature2(start_day, end_day):\n",
    "    register = user_register_log_df[user_register_log_df.register_day <= end_day][['user_id', 'register_day']]\n",
    "    retention = register.groupby(['register_day']).agg({'user_id': 'count'}).reset_index()\n",
    "    for day_cell in [1, 3, 7]:\n",
    "        app_temp_df = app_launch_log_df[app_launch_log_df.day == end_day - day_cell + 1][['user_id']]\n",
    "        video_temp_df = video_create_log_df[video_create_log_df.day == end_day - day_cell + 1][['user_id']]\n",
    "        action_temp_df = user_activity_log_df[user_activity_log_df.day == end_day - day_cell + 1][['user_id']]\n",
    "        active_temp = pd.concat([app_temp_df, video_temp_df, action_temp_df], axis=0).drop_duplicates()\n",
    "        retention_temp = pd.merge(active_temp, register, on=['user_id'], how='left')\n",
    "        retention_temp = retention_temp.groupby(['register_day']).agg('count').reset_index()\n",
    "        retention_temp.rename(columns={'user_id': 'r_retention_at_' + str(day_cell)}, inplace=True)\n",
    "        retention = pd.merge(retention, retention_temp, on=['register_day'], how='left')\n",
    "        retention['r_retention_at_' + str(day_cell)] = retention['r_retention_at_' + str(day_cell)] / retention.user_id\n",
    "   \n",
    "    return retention.drop(['user_id'], axis=1).fillna(0)\n",
    "\n",
    "\n",
    "# 注册日次日、3天、7天、观测点(end_day)留存率\n",
    "def get_register_retention_feature3(start_day, end_day):\n",
    "    register = user_register_log_df[user_register_log_df.register_day <= end_day][['user_id', 'register_day']]\n",
    "    app_temp_df = app_launch_log_df[app_launch_log_df.day <= end_day][['user_id', 'day']]\n",
    "    video_temp_df = video_create_log_df[video_create_log_df.day <= end_day][['user_id', 'day']]\n",
    "    action_temp_df = user_activity_log_df[user_activity_log_df.day <= end_day][['user_id', 'day']]\n",
    "    active_temp = pd.concat([app_temp_df, video_temp_df, action_temp_df], axis=0).drop_duplicates()\n",
    "    retention_temp = pd.merge(active_temp, register, on=['user_id'], how='left')\n",
    "    retention_temp = retention_temp.groupby(['register_day', 'day']).agg('count').reset_index()\n",
    "    retention_temp.rename(columns={'user_id': 'cnt'}, inplace=True)\n",
    "    retention = register.groupby(['register_day']).agg({'user_id': 'count'}).reset_index()\n",
    "    for day in [1, 3, 7, end_day]:\n",
    "        if day!=end_day:\n",
    "            retention['r_' + str(day) + '_retention'] = retention.register_day.apply(\n",
    "                lambda x: x + day if (x + day) < end_day else end_day)\n",
    "            retention = pd.merge(retention, retention_temp, left_on=['register_day', 'r_' + str(day) + '_retention'],\n",
    "                                 right_on=['register_day', 'day'], how='left')\n",
    "            retention['r_' + str(day) + '_retention'] = retention.cnt / retention.user_id\n",
    "            retention = retention.drop(['cnt', 'day'], axis=1)\n",
    "        else:\n",
    "            retention['r_endday_retention'] = retention.register_day.apply(\n",
    "                lambda x: x + day if (x + day) < end_day else end_day)\n",
    "            retention = pd.merge(retention, retention_temp, left_on=['register_day','r_endday_retention'],\n",
    "                                 right_on=['register_day', 'day'], how='left')\n",
    "            retention['r_endday_retention'] = retention.cnt / retention.user_id\n",
    "            retention = retention.drop(['cnt', 'day'], axis=1)\n",
    "    return retention.drop(['user_id'], axis=1).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_train_data(start_day,end_day):\n",
    "    #注册特征群\n",
    "    register=get_register_feature(start_day,end_day)\n",
    "    \n",
    "    #标签\n",
    "    label=get_label(end_day+1,end_day+7)\n",
    "    \n",
    "    #启动特征群\n",
    "    launch1=get_launch_cnt_feature1(start_day,end_day)\n",
    "    launch2=get_launch_cnt_feature2(start_day,end_day)\n",
    "    launch3=get_launch_day_feature1(start_day,end_day)\n",
    "    \n",
    "    #拍摄特征群\n",
    "    video1=get_video_cnt_feature1(start_day,end_day)\n",
    "    video2=get_video_cnt_feature2(start_day,end_day)\n",
    "    video3=get_video_day_feature1(start_day,end_day)\n",
    "\n",
    "    #行为特征群\n",
    "    action1=get_action_cnt_feature1(start_day,end_day)\n",
    "    action2=get_action_cnt_feature2(start_day,end_day)\n",
    "    action3=get_action_day_feature1(start_day,end_day)\n",
    "#     action4=get_action_author_feature(start_day,end_day)\n",
    "    action5=get_action_video_author_feature(start_day,end_day)\n",
    "    \n",
    "    #行为page特征群\n",
    "    page1=get_action_page_feature1(start_day,end_day)\n",
    "    page2=get_action_page_feature2(start_day,end_day)\n",
    "    \n",
    "    #行为actiontype特征群\n",
    "    atype1=get_action_atype_feature1(start_day,end_day)\n",
    "    atype2=get_action_atype_feature2(start_day,end_day)\n",
    "    \n",
    "    #cnt差分特征\n",
    "    cnt_diff1=get_video_cnt_diff_feature(start_day,end_day)\n",
    "    cnt_diff2=get_action_cnt_diff_feature(start_day,end_day)\n",
    "    \n",
    "    #day差分特征 不去重\n",
    "    day_diff1=get_launch_day_diff_feature(start_day,end_day)\n",
    "    day_diff2=get_video_day_diff_feature(start_day,end_day)\n",
    "    day_diff3=get_action_day_diff_feature(start_day,end_day)\n",
    "    \n",
    "    #留存特征\n",
    "    retention1=get_register_retention_feature1(start_day,end_day)\n",
    "    retention2=get_register_retention_feature2(start_day,end_day)\n",
    "    retention3=get_register_retention_feature3(start_day,end_day)\n",
    "\n",
    "    #被行为特征\n",
    "#     actioned1=get_actioned_cnt_feature(start_day,end_day)\n",
    "    \n",
    "    data=pd.merge(register,launch1,on=['user_id'],how='left').fillna(0)\n",
    "    data=pd.merge(data,launch2,on=['user_id'],how='left').fillna(0)\n",
    "    data=pd.merge(data,launch3,on=['user_id'],how='left').fillna(-1)\n",
    "    \n",
    "    data=pd.merge(data,video1,on=['user_id'],how='left').fillna(0)\n",
    "    data=pd.merge(data,video2,on=['user_id'],how='left').fillna(0)\n",
    "    data=pd.merge(data,video3,on=['user_id'],how='left').fillna(-1)\n",
    "\n",
    "    data=pd.merge(data,action1,on=['user_id'],how='left').fillna(0)\n",
    "    data=pd.merge(data,action2,on=['user_id'],how='left').fillna(0)\n",
    "    data=pd.merge(data,action3,on=['user_id'],how='left').fillna(-1)\n",
    "#     data=pd.merge(data,action4,on=['user_id'],how='left').fillna(0)\n",
    "    data=pd.merge(data,action5,on=['user_id'],how='left').fillna(0)\n",
    "\n",
    "#     data=pd.merge(data,actioned1,on=['user_id'],how='left').fillna(0)\n",
    "    \n",
    "    data=pd.merge(data,page1,on=['user_id'],how='left').fillna(0)\n",
    "    data=pd.merge(data,page2,on=['user_id'],how='left').fillna(0)\n",
    "    \n",
    "    data=pd.merge(data,atype1,on=['user_id'],how='left').fillna(0)\n",
    "    data=pd.merge(data,atype2,on=['user_id'],how='left').fillna(0)\n",
    "    \n",
    "    data=pd.merge(data,retention1,on=['register_day'],how='left').fillna(0)\n",
    "    data=pd.merge(data,retention2,on=['register_day'],how='left').fillna(0)\n",
    "    data=pd.merge(data,retention3,on=['register_day'],how='left').fillna(0)\n",
    "    \n",
    "    data=pd.merge(data,cnt_diff1,on=['user_id'],how='left')\n",
    "    data=pd.merge(data,cnt_diff2,on=['user_id'],how='left')\n",
    "    \n",
    "    data=pd.merge(data,day_diff1,on=['user_id'],how='left')\n",
    "    data=pd.merge(data,day_diff2,on=['user_id'],how='left')\n",
    "    data=pd.merge(data,day_diff3,on=['user_id'],how='left')\n",
    "    \n",
    "    data=pd.merge(data,label,on=['user_id'],how='left')\n",
    "    data.label=data.label.apply(lambda x: x if x==1 else 0)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_test_data(start_day,end_day):\n",
    "    #注册特征群\n",
    "    register=get_register_feature(start_day,end_day)\n",
    "    \n",
    "    #启动特征群\n",
    "    launch1=get_launch_cnt_feature1(start_day,end_day)\n",
    "    launch2=get_launch_cnt_feature2(start_day,end_day)\n",
    "    launch3=get_launch_day_feature1(start_day,end_day)\n",
    "    \n",
    "    #拍摄特征群\n",
    "    video1=get_video_cnt_feature1(start_day,end_day)\n",
    "    video2=get_video_cnt_feature2(start_day,end_day)\n",
    "    video3=get_video_day_feature1(start_day,end_day)\n",
    "\n",
    "    #行为特征群\n",
    "    action1=get_action_cnt_feature1(start_day,end_day)\n",
    "    action2=get_action_cnt_feature2(start_day,end_day)\n",
    "    action3=get_action_day_feature1(start_day,end_day)\n",
    "#     action4=get_action_author_feature(start_day,end_day)\n",
    "    action5=get_action_video_author_feature(start_day,end_day)\n",
    "    \n",
    "    #行为page特征群\n",
    "    page1=get_action_page_feature1(start_day,end_day)\n",
    "    page2=get_action_page_feature2(start_day,end_day)\n",
    "    \n",
    "    #行为actiontype特征群\n",
    "    atype1=get_action_atype_feature1(start_day,end_day)\n",
    "    atype2=get_action_atype_feature2(start_day,end_day)\n",
    "    \n",
    "    #cnt差分特征\n",
    "    cnt_diff1=get_video_cnt_diff_feature(start_day,end_day)\n",
    "    cnt_diff2=get_action_cnt_diff_feature(start_day,end_day)\n",
    "    \n",
    "    #day差分特征 不去重\n",
    "    day_diff1=get_launch_day_diff_feature(start_day,end_day)\n",
    "    day_diff2=get_video_day_diff_feature(start_day,end_day)\n",
    "    day_diff3=get_action_day_diff_feature(start_day,end_day)\n",
    "    \n",
    "    #留存特征\n",
    "    retention1=get_register_retention_feature1(start_day,end_day)\n",
    "    retention2=get_register_retention_feature2(start_day,end_day)\n",
    "    retention3=get_register_retention_feature3(start_day,end_day)\n",
    "    \n",
    "    #被行为特征\n",
    "#     actioned1=get_actioned_cnt_feature(start_day,end_day)\n",
    "    \n",
    "    data=pd.merge(register,launch1,on=['user_id'],how='left').fillna(0)\n",
    "    data=pd.merge(data,launch2,on=['user_id'],how='left').fillna(0)\n",
    "    data=pd.merge(data,launch3,on=['user_id'],how='left').fillna(-1)\n",
    "    \n",
    "    data=pd.merge(data,video1,on=['user_id'],how='left').fillna(0)\n",
    "    data=pd.merge(data,video2,on=['user_id'],how='left').fillna(0)\n",
    "    data=pd.merge(data,video3,on=['user_id'],how='left').fillna(-1)\n",
    "\n",
    "    data=pd.merge(data,action1,on=['user_id'],how='left').fillna(0)\n",
    "    data=pd.merge(data,action2,on=['user_id'],how='left').fillna(0)\n",
    "    data=pd.merge(data,action3,on=['user_id'],how='left').fillna(-1)\n",
    "#     data=pd.merge(data,action4,on=['user_id'],how='left').fillna(0)\n",
    "    data=pd.merge(data,action5,on=['user_id'],how='left').fillna(0)\n",
    "    \n",
    "#     data=pd.merge(data,actioned1,on=['user_id'],how='left').fillna(0)\n",
    "    \n",
    "    data=pd.merge(data,page1,on=['user_id'],how='left').fillna(0)\n",
    "    data=pd.merge(data,page2,on=['user_id'],how='left').fillna(0)\n",
    "    \n",
    "    data=pd.merge(data,atype1,on=['user_id'],how='left').fillna(0)\n",
    "    data=pd.merge(data,atype2,on=['user_id'],how='left').fillna(0)\n",
    "    \n",
    "    data=pd.merge(data,retention1,on=['register_day'],how='left').fillna(0)\n",
    "    data=pd.merge(data,retention2,on=['register_day'],how='left').fillna(0)\n",
    "    data=pd.merge(data,retention3,on=['register_day'],how='left').fillna(0)\n",
    "    \n",
    "    data=pd.merge(data,cnt_diff1,on=['user_id'],how='left')\n",
    "    data=pd.merge(data,cnt_diff2,on=['user_id'],how='left')\n",
    "    \n",
    "    data=pd.merge(data,day_diff1,on=['user_id'],how='left')\n",
    "    data=pd.merge(data,day_diff2,on=['user_id'],how='left')\n",
    "    data=pd.merge(data,day_diff3,on=['user_id'],how='left')\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========126s,data1 done,shape:(23923, 147)==========\n",
      "========199s,data2 done,shape:(37335, 147)==========\n",
      "========7s,train done,shape:(61258, 138)==========\n",
      "========268s,data3 done,shape:(51480, 146)==========\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    INPUT_BASE_PATH = r'../Data/raw_data_b'\n",
    "    OUTPUT_BASE_PATH = r'../Data/data_b'\n",
    "    \n",
    "    #加载数据\n",
    "    user_register_log_df,app_launch_log_df,video_create_log_df,user_activity_log_df=load_data(INPUT_BASE_PATH)\n",
    "    \n",
    "    #训练集\n",
    "    starttime = datetime.datetime.now()\n",
    "    train=get_train_data(1,16)\n",
    "    print('========'+str((datetime.datetime.now() - starttime).seconds)+'s,data1 done,shape:'+str(train.shape)+'==========')\n",
    "    \n",
    "    #验证集\n",
    "    starttime = datetime.datetime.now()\n",
    "    valid=get_train_data(8,23)\n",
    "    print('========'+str((datetime.datetime.now() - starttime).seconds)+'s,data2 done,shape:'+str(valid.shape)+'==========')\n",
    "        \n",
    "    #合并data1和data2\n",
    "    starttime = datetime.datetime.now()\n",
    "    df=pd.concat([train,valid],axis=0)\n",
    "    df=shuffle(df)\n",
    "    drop_columns=['a_a4_cnt_sum_in_1','a_a4_cnt_sum_in_16','a_a4_cnt_sum_in_3','a_a4_cnt_sum_in_7','a_a4_cnt_weight_sum','a_a4_weight','a_a5_cnt_sum_in_1','a_a5_cnt_sum_in_3','l_cnt_var']\n",
    "    df=df.drop(drop_columns,axis=1)\n",
    "    df.to_csv(OUTPUT_BASE_PATH+'/train.csv',index=False)\n",
    "    print('========'+str((datetime.datetime.now() - starttime).seconds)+'s,train done,shape:'+str(df.shape)+'==========')\n",
    "    \n",
    "    #测试集\n",
    "    starttime = datetime.datetime.now()\n",
    "    test=get_test_data(15,30)\n",
    "    test.to_csv(OUTPUT_BASE_PATH+'/test.csv',index=False)\n",
    "    print('========'+str((datetime.datetime.now() - starttime).seconds)+'s,data3 done,shape:'+str(test.shape)+'==========')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
